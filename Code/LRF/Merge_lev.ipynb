{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd281a3",
   "metadata": {},
   "source": [
    "## Regress moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b86c705",
   "metadata": {},
   "source": [
    "### Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e848654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os;\n",
    "import numpy as np;\n",
    "import xarray as xr;\n",
    "import pandas as pd;\n",
    "from glob import glob;\n",
    "from matplotlib import pyplot as plt;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f197d",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced3a944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/coding/times.py:358: CFWarning: this date/calendar/year zero convention is not supported by CF\n",
      "  cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)\n",
      "/tmp/ipykernel_3275303/1484541646.py:1: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates prior reform date (1582-10-15). To silence this warning specify 'use_cftime=True'.\n",
      "  ds = xr.open_mfdataset(\"/data92/b11209013/ERA5/File/t*.nc\", combine=\"by_coords\");\n",
      "/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/coding/times.py:358: CFWarning: this date/calendar/year zero convention is not supported by CF\n",
      "  cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)\n",
      "/tmp/ipykernel_3275303/1484541646.py:1: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates prior reform date (1582-10-15). To silence this warning specify 'use_cftime=True'.\n",
      "  ds = xr.open_mfdataset(\"/data92/b11209013/ERA5/File/t*.nc\", combine=\"by_coords\");\n",
      "/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/coding/times.py:358: CFWarning: this date/calendar/year zero convention is not supported by CF\n",
      "  cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)\n",
      "/tmp/ipykernel_3275303/1484541646.py:1: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates prior reform date (1582-10-15). To silence this warning specify 'use_cftime=True'.\n",
      "  ds = xr.open_mfdataset(\"/data92/b11209013/ERA5/File/t*.nc\", combine=\"by_coords\");\n",
      "/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/coding/times.py:358: CFWarning: this date/calendar/year zero convention is not supported by CF\n",
      "  cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)\n",
      "/tmp/ipykernel_3275303/1484541646.py:1: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates prior reform date (1582-10-15). To silence this warning specify 'use_cftime=True'.\n",
      "  ds = xr.open_mfdataset(\"/data92/b11209013/ERA5/File/t*.nc\", combine=\"by_coords\");\n",
      "/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/coding/times.py:358: CFWarning: this date/calendar/year zero convention is not supported by CF\n",
      "  cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)\n",
      "/tmp/ipykernel_3275303/1484541646.py:1: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates prior reform date (1582-10-15). To silence this warning specify 'use_cftime=True'.\n",
      "  ds = xr.open_mfdataset(\"/data92/b11209013/ERA5/File/t*.nc\", combine=\"by_coords\");\n",
      "/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/coding/times.py:358: CFWarning: this date/calendar/year zero convention is not supported by CF\n",
      "  cftime.num2date(num_dates, units, calendar, only_use_cftime_datetimes=True)\n",
      "/tmp/ipykernel_3275303/1484541646.py:1: SerializationWarning: Unable to decode time axis into full numpy.datetime64 objects, continuing using cftime.datetime objects instead, reason: dates prior reform date (1582-10-15). To silence this warning specify 'use_cftime=True'.\n",
      "  ds = xr.open_mfdataset(\"/data92/b11209013/ERA5/File/t*.nc\", combine=\"by_coords\");\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Coordinate variable time is neither monotonically increasing nor monotonically decreasing on all datasets",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_mfdataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/data92/b11209013/ERA5/File/t*.nc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mby_coords\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m;\n\u001b[32m      2\u001b[39m ds = ds.sortby(\u001b[33m\"\u001b[39m\u001b[33mplev\u001b[39m\u001b[33m\"\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m);\n\u001b[32m      4\u001b[39m new_time = pd.date_range(start=\u001b[33m\"\u001b[39m\u001b[33m1979-01-01\u001b[39m\u001b[33m\"\u001b[39m, periods=\u001b[38;5;28mlen\u001b[39m(ds.time), freq=\u001b[33m\"\u001b[39m\u001b[33m1D\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/backends/api.py:1663\u001b[39m, in \u001b[36mopen_mfdataset\u001b[39m\u001b[34m(paths, chunks, concat_dim, compat, preprocess, engine, data_vars, coords, combine, parallel, join, attrs_file, combine_attrs, **kwargs)\u001b[39m\n\u001b[32m   1650\u001b[39m     combined = _nested_combine(\n\u001b[32m   1651\u001b[39m         datasets,\n\u001b[32m   1652\u001b[39m         concat_dims=concat_dim,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1658\u001b[39m         combine_attrs=combine_attrs,\n\u001b[32m   1659\u001b[39m     )\n\u001b[32m   1660\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m combine == \u001b[33m\"\u001b[39m\u001b[33mby_coords\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1661\u001b[39m     \u001b[38;5;66;03m# Redo ordering from coordinates, ignoring how they were ordered\u001b[39;00m\n\u001b[32m   1662\u001b[39m     \u001b[38;5;66;03m# previously\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1663\u001b[39m     combined = \u001b[43mcombine_by_coords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1669\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1670\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1671\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1672\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1673\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcombine\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is an invalid option for the keyword argument ``combine``\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/structure/combine.py:983\u001b[39m, in \u001b[36mcombine_by_coords\u001b[39m\u001b[34m(data_objects, compat, data_vars, coords, fill_value, join, combine_attrs)\u001b[39m\n\u001b[32m    979\u001b[39m     grouped_by_vars = groupby_defaultdict(data_objects, key=vars_as_keys)\n\u001b[32m    981\u001b[39m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[32m    982\u001b[39m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m983\u001b[39m     concatenated_grouped_by_data_vars = \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    993\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mvars\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgrouped_by_vars\u001b[49m\n\u001b[32m    994\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[32m    997\u001b[39m     concatenated_grouped_by_data_vars,\n\u001b[32m    998\u001b[39m     compat=compat,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1001\u001b[39m     combine_attrs=combine_attrs,\n\u001b[32m   1002\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/structure/combine.py:984\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    979\u001b[39m     grouped_by_vars = groupby_defaultdict(data_objects, key=vars_as_keys)\n\u001b[32m    981\u001b[39m     \u001b[38;5;66;03m# Perform the multidimensional combine on each group of data variables\u001b[39;00m\n\u001b[32m    982\u001b[39m     \u001b[38;5;66;03m# before merging back together\u001b[39;00m\n\u001b[32m    983\u001b[39m     concatenated_grouped_by_data_vars = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m         \u001b[43m_combine_single_variable_hypercube\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets_with_same_vars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    987\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    989\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    990\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcombine_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    992\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    993\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mvars\u001b[39m, datasets_with_same_vars \u001b[38;5;129;01min\u001b[39;00m grouped_by_vars\n\u001b[32m    994\u001b[39m     )\n\u001b[32m    996\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[32m    997\u001b[39m     concatenated_grouped_by_data_vars,\n\u001b[32m    998\u001b[39m     compat=compat,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1001\u001b[39m     combine_attrs=combine_attrs,\n\u001b[32m   1002\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/structure/combine.py:645\u001b[39m, in \u001b[36m_combine_single_variable_hypercube\u001b[39m\u001b[34m(datasets, fill_value, data_vars, coords, compat, join, combine_attrs)\u001b[39m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(datasets) == \u001b[32m0\u001b[39m:\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    641\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAt least one Dataset is required to resolve variable names \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    642\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfor combined hypercube.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    643\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m645\u001b[39m combined_ids, concat_dims = \u001b[43m_infer_concat_order_from_coords\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    648\u001b[39m     \u001b[38;5;66;03m# check that datasets form complete hypercube\u001b[39;00m\n\u001b[32m    649\u001b[39m     _check_shape_tile_ids(combined_ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/b11209013/external/miniforge3/envs/atmo/lib/python3.11/site-packages/xarray/structure/combine.py:124\u001b[39m, in \u001b[36m_infer_concat_order_from_coords\u001b[39m\u001b[34m(datasets)\u001b[39m\n\u001b[32m    122\u001b[39m     ascending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    125\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCoordinate variable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is neither \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    126\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmonotonically increasing nor \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    127\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmonotonically decreasing on all datasets\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m     )\n\u001b[32m    130\u001b[39m \u001b[38;5;66;03m# Assume that any two datasets whose coord along dim starts\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# with the same value have the same coord values throughout.\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(index.size == \u001b[32m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m indexes):\n",
      "\u001b[31mValueError\u001b[39m: Coordinate variable time is neither monotonically increasing nor monotonically decreasing on all datasets"
     ]
    }
   ],
   "source": [
    "ds = xr.open_mfdataset(\"/data92/b11209013/ERA5/File/t*.nc\", combine=\"by_coords\");\n",
    "ds = ds.sortby(\"plev\", ascending=False);\n",
    "\n",
    "new_time = pd.date_range(start=\"1979-01-01\", periods=len(ds.time), freq=\"1D\")\n",
    "ds = ds.assign_coords(time=new_time)\n",
    "\n",
    "ds[\"time\"].attrs.update({\n",
    "    \"standard_name\": \"time\",\n",
    "    \"long_name\": \"time\",\n",
    "    \"axis\": \"T\"\n",
    "})\n",
    "\n",
    "encoding = {v: {\"zlib\": True, \"complevel\": 4} for v in ds.data_vars}\n",
    "encoding[\"time\"] = {\n",
    "    \"units\": \"days since 1979-01-01 00:00:00\",\n",
    "    \"calendar\": \"proleptic_gregorian\"\n",
    "}\n",
    "\n",
    "ds = ds.sel(plev=['250','500','700','850','925','1000']);\n",
    "\n",
    "ds.to_netcdf(\n",
    "    \"/data92/b11209013/ERA5/File/t.nc\",\n",
    "    format=\"NETCDF4\",\n",
    "    engine=\"netcdf4\",\n",
    "    unlimited_dims=[\"time\"],\n",
    "    encoding=encoding\n",
    "    );\n",
    "print(\"t_lev.nc done\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atmo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
